# Generating a Taxonomy of Museum Building Uses with LLMs

This project aimed to use large language models to generate structured, interpretable taxonomies from unstructured text describing museum buildings. It forms part of a wider pipeline for analysing the reasons for and outcomes of about 500 museum closures in the UK between 2000 and 2025. 

## Overview

The goal was to convert hundreds of semi-structured notes into a searchable database and visualisation platform used by non-technical stakeholders. To achieve this, I designed an automated pipeline that combines manual curation, LLM-assisted labelling, and clustering to extract and organise building-use information.

## Approach

1. **Data Preparation**  
   - Human-curated notes are stored in a spreadsheet with three main columns describing: the reasons why a museum closed, what happened to the museum's collection, and what happened to the museum's buildings.
   - A dataset of building notes was generated by taking the building notes column and augmenting notes with notes from other sources where they had been referred to.

2. **Supervised Prompt Tuning**  
   - Around 10% of notes were manually labelled across three dimensions based on the needs of experts researching museums:  
     - Change in *use*  
     - Change in *status*  
     - Change in *responsibility*  
   - These formed a support and evaluation set for selecting the best LLM + prompt + hyperparameters combination.

3. **Automated Labelling**  
   - Model performance was estimated by cosine similarity between embedding clusters of generated and human labels.
   - The best model was tasked with labelling the remaining data.
   - A random sample of the resulting labels was given to a human expert for evaluation. This ensures trust in the resulting LLM-generated output.

4. **Taxonomy Generation**  
   - Label embeddings were generated by augmenting labels with introductory text from a relevant Wikipedia article and embedding with an encoder model.
   - The label embeddings were used in k-means clustering to produce a smaller number of similar labels.
   - A generative LLM summarised each cluster into a concise label.  
   - The process was repeated hierarchically to produce a two-level taxonomy of types (core and specific).

## Outcome

- Produced a reusable **LLM-assisted taxonomy generation framework** applicable to other textual datasets.  
- The resulting taxonomy is being added to an interactive **Neo4j + Shiny** dashboard used by researchers and policy partners to explore changes in the museum sector.  
- This demonstrates that LLMs can reliably structure domain-specific text when grounded through prompt selection, embedding-based evaluation, and iterative clustering.


## Code

The code for the experiments and pipeline generation can be found on our [GitHub repository](https://github.com/Birkbeck/museum-object-flows/tree/automated-building-analysis/buildings-analysis)

This is part of a larger project in which I have developed a data analysis pipeline and interactive data exploration web application.

**Repository:** [github.com/Birkbeck/museum-object-flows](https://github.com/Birkbeck/museum-object-flows)  
**Role:** Full pipeline design, LLM integration, evaluation, and user-facing visualisation.
